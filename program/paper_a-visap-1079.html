<!DOCTYPE html><html lang="en"> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2024/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/1.12/auth0-spa-js.production.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2024/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2024/js/data/persistor.js"></script><script src="/static/2024/js/data/api.js"></script><link rel="shortcut icon" href="/static/2024/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2024/css/Zilla.css" rel="stylesheet"><link href="/static/2024/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2024/css/main.css"><link rel="stylesheet" href="/static/2024/css/fa_solid.css"><link rel="stylesheet" href="/static/2024/css/lazy_load.css"><link rel="stylesheet" href="/static/2024/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2024 - Paper: ReCollection"><meta name="twitter:description" content="This artwork was born of witnessing my grandmother's memory regression due to dementia, where her cherished stories dissolved into fragmented words. Dr. Mary Steedly once described memories as a &#34;densely layered, sometimes conflictual negotiation with the passage of time&#34;, and in 2022, over 50 million people faced this painful reality of memory loss due to Alzheimer's and related dementias. Yet, amidst this poignant backdrop, the emergence of text-to-image AI systems in 2022 offered a glimmer of new perspective, as they harnessed the power of language to imagine and reassemble fragmented memories, possibly to weave what time and disease had stolen.  ​ When we coexist with machines, will we accumulate synthetic recollections of collective symbiotic imagination? Is language capable of re-weaving and synthesizing memories? How does our collective memory inspire new visual forms and alternative narratives?  Recollection is an assemblage of intimate human-machine artifacts that emphasizes the contributions from three sides: artists, machines, and participants. This customized AI application facilitates multiple AI techniques, like speech recognition, text auto-completion, and text-to-image, to convert language input into image sequences of new memories. As an interactive experience, participants will whisper their personal memories with fragmented sentences, and our system will automatically fill in details, creating new touching visual memories.  We developed our customized AI system by fine-tuning a pre-trained transformer-based AI model to learn the documentaries of Alzheimer patients’ visual memories and their descriptions. The system imagines new memories of &#34;love&#34; and &#34;loss&#34; by interpreting real-time narratives from participants in the installation. Our system emerges as a vibrant and inclusive conversation starter, transcending boundaries with support for over 89 different languages, embracing the diverse cultural artifacts.   In the art installation, we chose not to showcase the direct visual output generated by our AI system. Instead, we drew inspiration from fine-art practices such as the Monotype, a printmaking technique tracing its origins to the 1640s, and slitscan photography, known for capturing sequential slices of a subject over time. We aimed to present ReCollection by combining generative methodologies with fine-art practices, investigating new aesthetics that explore the fleeting visual imagery, undergoing dissolution, tilting, printing, and reprinting over time.  By providing a conceptual framework for non-linear narratives, which constitute symbiotic imaginations, and future scenarios of memories, culture production, and reproductions. It may inspire the cure for memory regression by providing a future scenario, a thought experiment, and an intimate recollection of symbiosis between beings and apparatus. It raises people's awareness of future memory preservation and their empathy for the dementia community through a personalized aesthetic experience. It offers an artistic approach and future prototype for cultural heritage reproduction and re-imagination and explores the tensions that exist in the co-relations between visual representations, language, and narratives."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="This artwork was born of witnessing my grandmother's memory regression due to dementia, where her cherished stories dissolved into fragmented words. Dr. Mary Steedly once described memories as a &#34;densely layered, sometimes conflictual negotiation with the passage of time&#34;, and in 2022, over 50 million people faced this painful reality of memory loss due to Alzheimer's and related dementias. Yet, amidst this poignant backdrop, the emergence of text-to-image AI systems in 2022 offered a glimmer of new perspective, as they harnessed the power of language to imagine and reassemble fragmented memories, possibly to weave what time and disease had stolen.  ​ When we coexist with machines, will we accumulate synthetic recollections of collective symbiotic imagination? Is language capable of re-weaving and synthesizing memories? How does our collective memory inspire new visual forms and alternative narratives?  Recollection is an assemblage of intimate human-machine artifacts that emphasizes the contributions from three sides: artists, machines, and participants. This customized AI application facilitates multiple AI techniques, like speech recognition, text auto-completion, and text-to-image, to convert language input into image sequences of new memories. As an interactive experience, participants will whisper their personal memories with fragmented sentences, and our system will automatically fill in details, creating new touching visual memories.  We developed our customized AI system by fine-tuning a pre-trained transformer-based AI model to learn the documentaries of Alzheimer patients’ visual memories and their descriptions. The system imagines new memories of &#34;love&#34; and &#34;loss&#34; by interpreting real-time narratives from participants in the installation. Our system emerges as a vibrant and inclusive conversation starter, transcending boundaries with support for over 89 different languages, embracing the diverse cultural artifacts.   In the art installation, we chose not to showcase the direct visual output generated by our AI system. Instead, we drew inspiration from fine-art practices such as the Monotype, a printmaking technique tracing its origins to the 1640s, and slitscan photography, known for capturing sequential slices of a subject over time. We aimed to present ReCollection by combining generative methodologies with fine-art practices, investigating new aesthetics that explore the fleeting visual imagery, undergoing dissolution, tilting, printing, and reprinting over time.  By providing a conceptual framework for non-linear narratives, which constitute symbiotic imaginations, and future scenarios of memories, culture production, and reproductions. It may inspire the cure for memory regression by providing a future scenario, a thought experiment, and an intimate recollection of symbiosis between beings and apparatus. It raises people's awareness of future memory preservation and their empathy for the dementia community through a personalized aesthetic experience. It offers an artistic approach and future prototype for cultural heritage reproduction and re-imagination and explores the tensions that exist in the co-relations between visual representations, language, and narratives."><meta name="title" property="og:title" content="Virtual IEEE VIS 2024 - Paper: ReCollection"><meta property="og:type" content="website"><title>IEEE VIS 2024 Content: ReCollection</title></head> <body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style> <div class="container mb-5"> <div class="tabs"> </div> <div class="content"> <div class="row mt-3"> <div class="col-md-12"> <nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"> <ol class="breadcrumb"> <li class="breadcrumb-item"><a href="event_a-visap.html">VIS Arts Program</a> </li> <li class="breadcrumb-item"><a href="session_visapr.html">VISAP Opening Reception</a> </li> <li class="breadcrumb-item active text-truncate" aria-current="page">ReCollection</li> </ol> </nav> <h1 class="paper-title">ReCollection</h1> <div class="checkbox-bookmark fas" style="font-size: 24pt;position: absolute; top:10px; right:20px;" data-tippy-content="(un-)bookmark this paper"> &#xf02e; </div> <h4 class="paper-authors pb-2 mt-2"> <span class="fas mr-1">&#xf183;</span> <a href="mailto:weidizhang@ucsb.edu">weidi zhang</a> - Arizona State University, Tempe, United States </h4> <h4 class="paper-authors pb-2 mt-2"> <span class="fas mr-1">&#xf183;</span> Jieliang Luo - Independant Researcher, Beijing, China </h4> <h3 class="session-room mt-4"> <span class="fas mr-1">&#xf108;</span> <a href="room_bayshore3.html"> Room: Bayshore III </a> </h3> <h5 class="paper-presentation pb-2"> <span class="format-date">2024-10-15T23:30:00Z</span> <span alt="Change timezone on schedule page" class="timezone tztooltip"> <strong>GMT<span class="selectedTimezone">-0600</span></strong> <span class="tztooltiptext">Change your timezone on the schedule page</span> </span> <br> <span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"> <span class="relative-time">2024-10-15T23:30:00Z</span> <span class="current-time tztooltiptext"></span> </span> </h5> </div> </div> <div class="row my-3"> <div class="col-md-8"> </div> </div> <div class="row my-3"> <div class="col-md-8"> <h5 class="paper-details-heading">Abstract</h5> <p>This artwork was born of witnessing my grandmother&#39;s memory regression due to dementia, where her cherished stories dissolved into fragmented words. Dr. Mary Steedly once described memories as a &#34;densely layered, sometimes conflictual negotiation with the passage of time&#34;, and in 2022, over 50 million people faced this painful reality of memory loss due to Alzheimer&#39;s and related dementias. Yet, amidst this poignant backdrop, the emergence of text-to-image AI systems in 2022 offered a glimmer of new perspective, as they harnessed the power of language to imagine and reassemble fragmented memories, possibly to weave what time and disease had stolen. ​ When we coexist with machines, will we accumulate synthetic recollections of collective symbiotic imagination? Is language capable of re-weaving and synthesizing memories? How does our collective memory inspire new visual forms and alternative narratives? Recollection is an assemblage of intimate human-machine artifacts that emphasizes the contributions from three sides: artists, machines, and participants. This customized AI application facilitates multiple AI techniques, like speech recognition, text auto-completion, and text-to-image, to convert language input into image sequences of new memories. As an interactive experience, participants will whisper their personal memories with fragmented sentences, and our system will automatically fill in details, creating new touching visual memories. We developed our customized AI system by fine-tuning a pre-trained transformer-based AI model to learn the documentaries of Alzheimer patients’ visual memories and their descriptions. The system imagines new memories of &#34;love&#34; and &#34;loss&#34; by interpreting real-time narratives from participants in the installation. Our system emerges as a vibrant and inclusive conversation starter, transcending boundaries with support for over 89 different languages, embracing the diverse cultural artifacts. In the art installation, we chose not to showcase the direct visual output generated by our AI system. Instead, we drew inspiration from fine-art practices such as the Monotype, a printmaking technique tracing its origins to the 1640s, and slitscan photography, known for capturing sequential slices of a subject over time. We aimed to present ReCollection by combining generative methodologies with fine-art practices, investigating new aesthetics that explore the fleeting visual imagery, undergoing dissolution, tilting, printing, and reprinting over time. By providing a conceptual framework for non-linear narratives, which constitute symbiotic imaginations, and future scenarios of memories, culture production, and reproductions. It may inspire the cure for memory regression by providing a future scenario, a thought experiment, and an intimate recollection of symbiosis between beings and apparatus. It raises people&#39;s awareness of future memory preservation and their empathy for the dementia community through a personalized aesthetic experience. It offers an artistic approach and future prototype for cultural heritage reproduction and re-imagination and explores the tensions that exist in the co-relations between visual representations, language, and narratives.</p> </div> </div> <script lang="js">
      const paperID = "a-visap-1079"
      $(document).ready(() => {
        tippy('[data-tippy-content]');

        const allBookmarks =
          d3.selectAll('.checkbox-bookmark')
            .on("click", function () {
              const newValue = !d3.select(this).classed('selected');
              API.markSet(API.storeIDs.bookmarked, paperID, newValue);
              d3.select(this).classed('selected', newValue);
            })
        API.markGet(API.storeIDs.bookmarked, paperID).then(is_bookmarked => {
          is_bookmarked = !!is_bookmarked;
          allBookmarks.classed('selected', is_bookmarked);
        })
        API.markSet(API.storeIDs.visited, paperID, true);

      })

    </script> <script src="/static/2024/js/views/timezone.js"></script> </div> </div> <script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script> </body> </html>